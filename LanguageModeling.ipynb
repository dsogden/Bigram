{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTi9vvF5QN2aB03N1kDU/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsogden/Bigram/blob/main/LanguageModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "haMCDG7lwgvD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/names.txt'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "  names = f.read().splitlines()\n",
        "print(names[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOGK_u9Fw2Ei",
        "outputId": "af9d2745-f345-4f30-d173-975d5dc14de0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, names: list[str]):\n",
        "        self.chars = sorted(list(set(''.join(names))))\n",
        "        self.stoi = {s: i + 1 for i, s in enumerate(self.chars)}\n",
        "        self.stoi['.'] = 0\n",
        "        self.itos = {i: s for s, i in self.stoi.items()}\n",
        "        self.vocab_size = len(self.stoi)\n",
        "\n",
        "    def encode(self, name: str, max_length: int) -> list[int]:\n",
        "        padding = max_length - len(name)\n",
        "        return [self.stoi[c] for c in name] + [0] * (padding + 1)\n",
        "\n",
        "    def decode(self, tokens: list[int]) -> str:\n",
        "        return ''.join([self.itos[t] for t in tokens])"
      ],
      "metadata": {
        "id": "b53Un_-Iw-X5"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(names)\n",
        "max_length = max([len(name) for name in names])\n",
        "print(max_length)\n",
        "encoded = torch.tensor(\n",
        "    [tokenizer.encode(name, max_length) for name in names], dtype=torch.float32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlb6pAsxNLL",
        "outputId": "f4585ce6-71fd-4969-e759-0746c5935474"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l in F.log_softmax(logits(output), dim=-1).argmax(dim=-1):\n",
        "    print(tokenizer.decode(l.tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA3RC6-e1oba",
        "outputId": "11ec5cad-f55c-494b-80e4-b6d5d8e1a8e0"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15, 26, 13, 15, 7, 23, 13, 13, 26, 24, 13, 15, 24, 7, 24, 13, 24, 13, 7, 13, 26, 26, 7, 6, 6, 15, 24]\n",
            "None\n",
            "[26, 13, 6, 19, 25, 13, 6, 6, 13, 7, 6, 24, 25, 25, 8, 6, 8, 6, 25, 6, 13, 13, 25, 6, 26, 7, 2]\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoded[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LNkQJ4sL2CWS",
        "outputId": "220846d2-ee10-4f3a-98bb-01c53dc0a756"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emma............'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv1d(1, 27, 3, stride=1, bias=False)\n",
        "convolution = conv1(encoded[:1].unsqueeze(1))\n",
        "logits = nn.Linear(14, 27)\n",
        "output = F.log_softmax(logits(convolution), dim=-1).argmax(dim=-1)"
      ],
      "metadata": {
        "id": "CC9z-p7330kD"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(output.squeeze(0).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hiz9akGE4C_V",
        "outputId": "080943ab-729d-4ab1-c94f-bf51ff564873"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vmyojmcvbvocjovvccwvwvvmvvm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(1, 27, 3, stride=1, bias=False)\n",
        "        self.linear = nn.Linear(14, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x.unsqueeze(1))\n",
        "        return F.log_softmax(self.linear(x), dim=-1)"
      ],
      "metadata": {
        "id": "usGKWFOu4MTk"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    running_loss = 0.0\n",
        "    for idx, (X, y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X)\n",
        "        loss = criterion(y_pred, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / (idx + 1)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    running_loss = 0.0\n",
        "    for idx, (X, y) in enumerate(dataloader):\n",
        "        y_pred = model(X)\n",
        "        loss = criterion(y_pred, y.long())\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / (idx + 1)"
      ],
      "metadata": {
        "id": "evggrBct4u5Y"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = LanguageModel()\n",
        "test_model(encoded[:1]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZuIOJCs5cZs",
        "outputId": "28136555-9a98-4048-8155-354effa0c7a1"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 27, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    encoded, encoded, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "val_dataset = TensorDataset(x_val, y_val)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "jG2zSDES5FIS"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "epochs = 10\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR0WxW774sEn",
        "outputId": "fc659565-48da-457b-ecea-9324e42ee9e2"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 3.1435, Val Loss: 2.6778\n",
            "Epoch 2/10, Train Loss: 2.4493, Val Loss: 2.2997\n",
            "Epoch 3/10, Train Loss: 2.2501, Val Loss: 2.2247\n",
            "Epoch 4/10, Train Loss: 2.2042, Val Loss: 2.1909\n",
            "Epoch 5/10, Train Loss: 2.1714, Val Loss: 2.1587\n",
            "Epoch 6/10, Train Loss: 2.1411, Val Loss: 2.1303\n",
            "Epoch 7/10, Train Loss: 2.1157, Val Loss: 2.1078\n",
            "Epoch 8/10, Train Loss: 2.0959, Val Loss: 2.0914\n",
            "Epoch 9/10, Train Loss: 2.0818, Val Loss: 2.0800\n",
            "Epoch 10/10, Train Loss: 2.0719, Val Loss: 2.0716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_vals = encoded[100: 132]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)"
      ],
      "metadata": {
        "id": "RIn3SDwt5WBu"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for char in predicted_chars:\n",
        "    print(tokenizer.decode(char.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTTwCz2e6IXZ",
        "outputId": "3a8edf64-045f-425d-8c28-225ef23d2713"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ma.aaaa.bc..b.ec..bcbbbbbbb\n",
            "meaaaeaaa.aaaaaaaaaaaaaaaa.\n",
            "ebbbbbbbcd..cacc.cccccccccc\n",
            "gdbbddbdef.beceeeeeeeeeeeee\n",
            "hcccccccde..d.dd.dddddd.dd.\n",
            "jdbdddddefddfefffefffffffff\n",
            "gdddddddea.deceeaeeeeeeeeea\n",
            "hbbbbbbcdeccdcdddcddddddddd\n",
            "gdaddddaea....e...e..e...e.\n",
            "gb.bbbbbab..aaca.aa..ca..c.\n",
            "edadddddddaacaccabccccccccc\n",
            "ma.aaadcec..ebeebbbeeebeeeb\n",
            "hbccdbcddb.daaaaaaaaaaaaaaa\n",
            "gcaaacaadc..b.bb.bbbbbbbbbb\n",
            "j.bb..bcde.cdcddddddddddddd\n",
            "faaaaaaabcaabbbb.bbbbbbbbbb\n",
            "feacceaadb.aaadd.aa..a.....\n",
            "hcaaaaaada.aaada...........\n",
            "fcaaacaabbaababb.abbbbbbbbb\n",
            "gd.ddddded..c.ec..ecceeceec\n",
            "maaaaaa.bc..b.eb.bbbbbbbbbb\n",
            "ga.aaaabcd..cbcccbccccccccc\n",
            "hdaaaaaaaaaaaab..a.........\n",
            "meaaabaaab.aaaaa.aa..aa....\n",
            "md.bddbbcd..c.gcccccccccccc\n",
            "gaaaaaaabc..cbcccbccccccccc\n",
            "mdddddddec..ebgeebegegeegge\n",
            "headddaaabaaaaaaaaaaaaaaaaa\n",
            "md.dddddeb..e.ee..eeeeeeeee\n",
            "ebbbbbbbcd..c.ccccccccccccc\n",
            "gdaabdabcd..c.cc..ccccccccc\n",
            "jcccccc.db..d.ee..dee......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MOpdTwG6Ktx",
        "outputId": "8e7d6524-6a18-407f-9877-7fa1be0ca032"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 3.5358, Val Loss: 2.8073\n",
            "Epoch 2/100, Train Loss: 2.6212, Val Loss: 2.4588\n",
            "Epoch 3/100, Train Loss: 2.3075, Val Loss: 2.2150\n",
            "Epoch 4/100, Train Loss: 2.1805, Val Loss: 2.1530\n",
            "Epoch 5/100, Train Loss: 2.1255, Val Loss: 2.1001\n",
            "Epoch 6/100, Train Loss: 2.0780, Val Loss: 2.0604\n",
            "Epoch 7/100, Train Loss: 2.0486, Val Loss: 2.0401\n",
            "Epoch 8/100, Train Loss: 2.0330, Val Loss: 2.0282\n",
            "Epoch 9/100, Train Loss: 2.0229, Val Loss: 2.0202\n",
            "Epoch 10/100, Train Loss: 2.0161, Val Loss: 2.0145\n",
            "Epoch 11/100, Train Loss: 2.0109, Val Loss: 2.0099\n",
            "Epoch 12/100, Train Loss: 2.0069, Val Loss: 2.0066\n",
            "Epoch 13/100, Train Loss: 2.0037, Val Loss: 2.0036\n",
            "Epoch 14/100, Train Loss: 2.0013, Val Loss: 2.0012\n",
            "Epoch 15/100, Train Loss: 1.9989, Val Loss: 1.9993\n",
            "Epoch 16/100, Train Loss: 1.9969, Val Loss: 1.9975\n",
            "Epoch 17/100, Train Loss: 1.9950, Val Loss: 1.9958\n",
            "Epoch 18/100, Train Loss: 1.9938, Val Loss: 1.9945\n",
            "Epoch 19/100, Train Loss: 1.9922, Val Loss: 1.9931\n",
            "Epoch 20/100, Train Loss: 1.9911, Val Loss: 1.9919\n",
            "Epoch 21/100, Train Loss: 1.9899, Val Loss: 1.9911\n",
            "Epoch 22/100, Train Loss: 1.9890, Val Loss: 1.9902\n",
            "Epoch 23/100, Train Loss: 1.9882, Val Loss: 1.9893\n",
            "Epoch 24/100, Train Loss: 1.9872, Val Loss: 1.9886\n",
            "Epoch 25/100, Train Loss: 1.9865, Val Loss: 1.9876\n",
            "Epoch 26/100, Train Loss: 1.9858, Val Loss: 1.9871\n",
            "Epoch 27/100, Train Loss: 1.9852, Val Loss: 1.9863\n",
            "Epoch 28/100, Train Loss: 1.9846, Val Loss: 1.9855\n",
            "Epoch 29/100, Train Loss: 1.9842, Val Loss: 1.9851\n",
            "Epoch 30/100, Train Loss: 1.9832, Val Loss: 1.9848\n",
            "Epoch 31/100, Train Loss: 1.9828, Val Loss: 1.9844\n",
            "Epoch 32/100, Train Loss: 1.9825, Val Loss: 1.9839\n",
            "Epoch 33/100, Train Loss: 1.9822, Val Loss: 1.9834\n",
            "Epoch 34/100, Train Loss: 1.9816, Val Loss: 1.9831\n",
            "Epoch 35/100, Train Loss: 1.9814, Val Loss: 1.9831\n",
            "Epoch 36/100, Train Loss: 1.9813, Val Loss: 1.9823\n",
            "Epoch 37/100, Train Loss: 1.9806, Val Loss: 1.9822\n",
            "Epoch 38/100, Train Loss: 1.9804, Val Loss: 1.9815\n",
            "Epoch 39/100, Train Loss: 1.9801, Val Loss: 1.9817\n",
            "Epoch 40/100, Train Loss: 1.9799, Val Loss: 1.9809\n",
            "Epoch 41/100, Train Loss: 1.9797, Val Loss: 1.9808\n",
            "Epoch 42/100, Train Loss: 1.9795, Val Loss: 1.9803\n",
            "Epoch 43/100, Train Loss: 1.9793, Val Loss: 1.9802\n",
            "Epoch 44/100, Train Loss: 1.9788, Val Loss: 1.9800\n",
            "Epoch 45/100, Train Loss: 1.9786, Val Loss: 1.9798\n",
            "Epoch 46/100, Train Loss: 1.9784, Val Loss: 1.9796\n",
            "Epoch 47/100, Train Loss: 1.9784, Val Loss: 1.9798\n",
            "Epoch 48/100, Train Loss: 1.9779, Val Loss: 1.9793\n",
            "Epoch 49/100, Train Loss: 1.9776, Val Loss: 1.9796\n",
            "Epoch 50/100, Train Loss: 1.9776, Val Loss: 1.9789\n",
            "Epoch 51/100, Train Loss: 1.9775, Val Loss: 1.9781\n",
            "Epoch 52/100, Train Loss: 1.9771, Val Loss: 1.9781\n",
            "Epoch 53/100, Train Loss: 1.9769, Val Loss: 1.9780\n",
            "Epoch 54/100, Train Loss: 1.9764, Val Loss: 1.9777\n",
            "Epoch 55/100, Train Loss: 1.9764, Val Loss: 1.9783\n",
            "Epoch 56/100, Train Loss: 1.9760, Val Loss: 1.9777\n",
            "Epoch 57/100, Train Loss: 1.9760, Val Loss: 1.9779\n",
            "Epoch 58/100, Train Loss: 1.9758, Val Loss: 1.9775\n",
            "Epoch 59/100, Train Loss: 1.9756, Val Loss: 1.9774\n",
            "Epoch 60/100, Train Loss: 1.9759, Val Loss: 1.9769\n",
            "Epoch 61/100, Train Loss: 1.9754, Val Loss: 1.9767\n",
            "Epoch 62/100, Train Loss: 1.9752, Val Loss: 1.9771\n",
            "Epoch 63/100, Train Loss: 1.9752, Val Loss: 1.9765\n",
            "Epoch 64/100, Train Loss: 1.9749, Val Loss: 1.9763\n",
            "Epoch 65/100, Train Loss: 1.9750, Val Loss: 1.9765\n",
            "Epoch 66/100, Train Loss: 1.9750, Val Loss: 1.9762\n",
            "Epoch 67/100, Train Loss: 1.9747, Val Loss: 1.9764\n",
            "Epoch 68/100, Train Loss: 1.9748, Val Loss: 1.9761\n",
            "Epoch 69/100, Train Loss: 1.9747, Val Loss: 1.9767\n",
            "Epoch 70/100, Train Loss: 1.9747, Val Loss: 1.9756\n",
            "Epoch 71/100, Train Loss: 1.9743, Val Loss: 1.9753\n",
            "Epoch 72/100, Train Loss: 1.9743, Val Loss: 1.9758\n",
            "Epoch 73/100, Train Loss: 1.9742, Val Loss: 1.9755\n",
            "Epoch 74/100, Train Loss: 1.9743, Val Loss: 1.9757\n",
            "Epoch 75/100, Train Loss: 1.9741, Val Loss: 1.9754\n",
            "Epoch 76/100, Train Loss: 1.9744, Val Loss: 1.9748\n",
            "Epoch 77/100, Train Loss: 1.9740, Val Loss: 1.9757\n",
            "Epoch 78/100, Train Loss: 1.9744, Val Loss: 1.9759\n",
            "Epoch 79/100, Train Loss: 1.9739, Val Loss: 1.9753\n",
            "Epoch 80/100, Train Loss: 1.9736, Val Loss: 1.9753\n",
            "Epoch 81/100, Train Loss: 1.9737, Val Loss: 1.9760\n",
            "Epoch 82/100, Train Loss: 1.9735, Val Loss: 1.9755\n",
            "Epoch 83/100, Train Loss: 1.9735, Val Loss: 1.9759\n",
            "Epoch 84/100, Train Loss: 1.9738, Val Loss: 1.9749\n",
            "Epoch 85/100, Train Loss: 1.9734, Val Loss: 1.9753\n",
            "Epoch 86/100, Train Loss: 1.9735, Val Loss: 1.9748\n",
            "Epoch 87/100, Train Loss: 1.9735, Val Loss: 1.9749\n",
            "Epoch 88/100, Train Loss: 1.9733, Val Loss: 1.9753\n",
            "Epoch 89/100, Train Loss: 1.9734, Val Loss: 1.9750\n",
            "Epoch 90/100, Train Loss: 1.9735, Val Loss: 1.9749\n",
            "Epoch 91/100, Train Loss: 1.9735, Val Loss: 1.9752\n",
            "Epoch 92/100, Train Loss: 1.9735, Val Loss: 1.9742\n",
            "Epoch 93/100, Train Loss: 1.9732, Val Loss: 1.9746\n",
            "Epoch 94/100, Train Loss: 1.9732, Val Loss: 1.9746\n",
            "Epoch 95/100, Train Loss: 1.9733, Val Loss: 1.9744\n",
            "Epoch 96/100, Train Loss: 1.9730, Val Loss: 1.9746\n",
            "Epoch 97/100, Train Loss: 1.9728, Val Loss: 1.9739\n",
            "Epoch 98/100, Train Loss: 1.9730, Val Loss: 1.9738\n",
            "Epoch 99/100, Train Loss: 1.9732, Val Loss: 1.9740\n",
            "Epoch 100/100, Train Loss: 1.9732, Val Loss: 1.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_vals = encoded[100: 132]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars:\n",
        "    print(tokenizer.decode(char.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYnkYiUK6TZS",
        "outputId": "571d93ef-62af-4d85-eb67-0cee7d41f9ba"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jfaaaa.aed..b.eb.bbbbbbbbbb\n",
            "heeeccccdc..aaa.a.aaaaaaaaa\n",
            "eb...b.babaacaccccccccccccc\n",
            "ffaaadaa.d..e.edeeeeeeeeeee\n",
            "hccccc.cbc..b.dd.d..dd...d.\n",
            "iaaaabaaae....fe.efffffffff\n",
            "fdbbbdabad....e............\n",
            "g....b..ac..daddddddddddddd\n",
            "hddddd.acd..b.eb.bbbeee..ee\n",
            "f....b..abaacaccacaaaaaaaaa\n",
            "daaaaaaacb.................\n",
            "iaaaaa.acd..b.ebbbbbbbbbbbb\n",
            "hbbbbbbbb.aaaaa.a.aaaaaaaaa\n",
            "gaaaca.aba..b.bbbbbbbbbbbbb\n",
            "haaaacaaac..d.dd.dddddddddd\n",
            "faaaaaaaca..b.bb.bbbbbbbbbb\n",
            "f.......bc.aaadaaaaaaaaaaaa\n",
            "heaeecacbc....d............\n",
            "fc..cc..ca..bbbababbbbbbbbb\n",
            "gdaaadaacb..c.cb.b..ee...e.\n",
            "jaaaaaaa.d..b.eb.bbbbbbbbbb\n",
            "faaaab.a.b..c.ccccccccccccc\n",
            "hdddddccca..b.ba..bbbbb..bb\n",
            "ie.eec.cdb..aaaaaaaaaaaaaaa\n",
            "id...d..cb.acccbcbccccccccc\n",
            "jaaaaaaadb..c.cbcbccccccccc\n",
            "laaaad.acd..b.gb.bbbbbggggg\n",
            "ecccccccc...aaaaaaaaaaaaaaa\n",
            "f....d..cd.aaaedaaeeeeeeeee\n",
            "fb...b..abaaccccccccccccccc\n",
            "fd..db..db..cccbcbccccccccc\n",
            "ic...c..bd..aaedaaaaaaaaaaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(1, 27, 3, stride=1, bias=False)\n",
        "        self.proj = nn.Linear(14, 128)\n",
        "        self.linear = nn.Linear(128, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x.unsqueeze(1))\n",
        "        x = F.relu(self.proj(x))\n",
        "        return F.log_softmax(self.linear(x), dim=-1)"
      ],
      "metadata": {
        "id": "K93Ji0NB6YIj"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFHKWXUo6yoH",
        "outputId": "62b79796-f73a-4954-9d7a-49b2efc9eb08"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 2.4606, Val Loss: 2.2402\n",
            "Epoch 11/100, Train Loss: 1.9171, Val Loss: 1.9157\n",
            "Epoch 21/100, Train Loss: 1.8335, Val Loss: 1.8341\n",
            "Epoch 31/100, Train Loss: 1.7631, Val Loss: 1.7669\n",
            "Epoch 41/100, Train Loss: 1.7252, Val Loss: 1.7309\n",
            "Epoch 51/100, Train Loss: 1.6989, Val Loss: 1.7039\n",
            "Epoch 61/100, Train Loss: 1.6850, Val Loss: 1.6950\n",
            "Epoch 71/100, Train Loss: 1.6730, Val Loss: 1.6794\n",
            "Epoch 81/100, Train Loss: 1.6636, Val Loss: 1.6711\n",
            "Epoch 91/100, Train Loss: 1.6571, Val Loss: 1.6674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_vals = encoded[100: 132]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars:\n",
        "    print(tokenizer.decode(char.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INFpE5jO62rZ",
        "outputId": "51f08564-8844-4eaa-a21a-4dc30499ed82"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mffaaaaaaadde.ed..ccccbbbbb\n",
            "jeeddcdddbbbbabab....aaaaaa\n",
            "jbb......aaaaaaaaaccccccccc\n",
            "maabbddb...cc.cccccceeeeeee\n",
            "mccffffffeebb.dd.dd..d...b.\n",
            "mabbddhhhghce.eeeeee.f..fff\n",
            "mdbaaaaccccce.eee....e...e.\n",
            "m..aaaaaafffc.ceefcccdddddd\n",
            "mdffffaaaccbb.eeeeee.e...e.\n",
            "j.bbdddeeeeecacacccccaaaaaa\n",
            "eaabbccccc.c....aa.........\n",
            "mahhhdhhcff.g.geheebbbbbbgb\n",
            "mbccddddg...eaaaefaaaaaaaaa\n",
            "hcffffffeeedd..b..bbbbbbbbb\n",
            "maabbbbbbbfcc.eec....d.dddd\n",
            "jaaaaaaecccc...b.bbbbbbbbbb\n",
            "j.eeeccbbbbbdadaddaaaaaaaaa\n",
            "jeeeeccaaaaad.ddddb..d...d.\n",
            "dcccceeeeeeeaaaaaaaaaabbbbb\n",
            "mddaaaaffbbbc.eeeee..c...c.\n",
            "maaaaaffadccc.eddeeeebbbbbb\n",
            "jaaaad..dbbbb.bcbbccccccccc\n",
            "jeeeccccccca...ba.bbbbbbbbb\n",
            "jedddddddcc.bababbaaaaaaaaa\n",
            "mdhffbbbbaaaaaaaeeaccacccgc\n",
            "daaeeeeeeee....b.bbbbcccccc\n",
            "mdaffffcccccg.ee.ebbbebbbgb\n",
            "jcccccbbbbbb.a.abbaaaaaaaaa\n",
            "m..dddbbbbbbcacaccaaaaaaaea\n",
            "j.bbbbbbbaaaaaaaaaaaaaacccc\n",
            "jdddd..bbbbaacaaaaacccccccc\n",
            "hc...bbbbbbbbadadeaaaaaaaaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add embedding layer\n",
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(27, 27)\n",
        "        self.conv = nn.Conv1d(16, 27, 3, stride=1, bias=False)\n",
        "        self.proj = nn.Linear(25, 128)\n",
        "        self.output = nn.Linear(128, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.long())\n",
        "        convolution = self.conv(x)\n",
        "        projection = F.relu(self.proj(convolution))\n",
        "        return F.log_softmax(self.output(projection), dim=-1)"
      ],
      "metadata": {
        "id": "BL4uSKyy7oiM"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-6-ZNwe721w",
        "outputId": "0981de31-c69f-4af8-e487-138de57ec069"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100, Train Loss: 2.1780, Val Loss: 1.9869\n",
            "Epoch 10/100, Train Loss: 1.7119, Val Loss: 1.7151\n",
            "Epoch 20/100, Train Loss: 1.6672, Val Loss: 1.6727\n",
            "Epoch 30/100, Train Loss: 1.6464, Val Loss: 1.6540\n",
            "Epoch 40/100, Train Loss: 1.6335, Val Loss: 1.6468\n",
            "Epoch 50/100, Train Loss: 1.6252, Val Loss: 1.6362\n",
            "Epoch 60/100, Train Loss: 1.6190, Val Loss: 1.6314\n",
            "Epoch 70/100, Train Loss: 1.6145, Val Loss: 1.6278\n",
            "Epoch 80/100, Train Loss: 1.6098, Val Loss: 1.6229\n",
            "Epoch 90/100, Train Loss: 1.6066, Val Loss: 1.6232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = tokenizer.itos\n",
        "with torch.no_grad():\n",
        "    random_vals = encoded[:32]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars:\n",
        "    string = ''\n",
        "    for letter in char.tolist():\n",
        "        if letter == 0:\n",
        "            break\n",
        "        string += decoder[letter]\n",
        "    print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne37XyFi96MK",
        "outputId": "2c358bea-2515-4e5c-a8bf-a73ca1115988"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcabb\n",
            "fec\n",
            "fbabcbabb\n",
            "hbcaedc\n",
            "fecbbccbcdcebceab\n",
            "ibc\n",
            "fb\n",
            "f\n",
            "fabbcdcb\n",
            "f\n",
            "jdacceacgbccfafb\n",
            "f\n",
            "jdecg\n",
            "mc\n",
            "mcaba\n",
            "f\n",
            "fdbbbbbb\n",
            "fec\n",
            "fcaca\n",
            "jbcagecgafdadadcbcc\n",
            "jg\n",
            "ha\n",
            "dcbbbabb\n",
            "fbcc\n",
            "fbc\n",
            "hdbfffffgg\n",
            "fabbcbbccbbc\n",
            "faccacbccabbbbfdbb\n",
            "fdc\n",
            "fcbbbadbd\n",
            "ed\n",
            "hcacfbacf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change projection to GRU\n",
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(27, 27)\n",
        "        self.conv = nn.Conv1d(16, 27, 2, stride=1, bias=False)\n",
        "        self.rnn = nn.GRU(26, 128, batch_first=True)\n",
        "        self.output = nn.Linear(128, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.long())\n",
        "        convolution = self.conv(x)\n",
        "        projection, _ = self.rnn(convolution)\n",
        "        return F.log_softmax(self.output(projection), dim=-1)"
      ],
      "metadata": {
        "id": "uljOw6cq-9BO"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZMRI0W4_yfx",
        "outputId": "9fe4b76a-2c9b-4dca-dcd2-5d4c618530b8"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100, Train Loss: 2.1911, Val Loss: 1.9441\n",
            "Epoch 10/100, Train Loss: 1.5369, Val Loss: 1.5475\n",
            "Epoch 20/100, Train Loss: 1.5173, Val Loss: 1.5321\n",
            "Epoch 30/100, Train Loss: 1.5102, Val Loss: 1.5283\n",
            "Epoch 40/100, Train Loss: 1.5071, Val Loss: 1.5270\n",
            "Epoch 50/100, Train Loss: 1.5049, Val Loss: 1.5260\n",
            "Epoch 60/100, Train Loss: 1.5034, Val Loss: 1.5253\n",
            "Epoch 70/100, Train Loss: 1.5034, Val Loss: 1.5247\n",
            "Epoch 80/100, Train Loss: 1.5027, Val Loss: 1.5249\n",
            "Epoch 90/100, Train Loss: 1.5020, Val Loss: 1.5243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_vals = encoded[:32]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars:\n",
        "    string = ''\n",
        "    for letter in char.tolist():\n",
        "        if letter == 0:\n",
        "            break\n",
        "        string += decoder[letter]\n",
        "    print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CblnqqC5_9_Q",
        "outputId": "57d01ba6-191e-4f49-d5a4-0458e4555bc1"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eca\n",
            "fea\n",
            "ebaaaaaabbaaaaabccba\n",
            "kgcccdaba\n",
            "gebd\n",
            "lbg\n",
            "ebccca\n",
            "jeabbbadddbacaa\n",
            "gaccddd\n",
            "gac\n",
            "odaaaacccecffaac\n",
            "eac\n",
            "odee\n",
            "hc\n",
            "eca\n",
            "e\n",
            "fdbb\n",
            "ged\n",
            "ecdcebabbbadaaaccaaaabbacbf\n",
            "jb\n",
            "lgbb\n",
            "ha\n",
            "fcc\n",
            "ebcccd\n",
            "had\n",
            "ja\n",
            "eac\n",
            "fabcccca\n",
            "ea\n",
            "fc\n",
            "ea\n",
            "jca\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove embedding and add more layers to GRU\n",
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, num_embeddings, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings, hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, hidden_dim, num_layers=4, batch_first=True)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.long())\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        output = self.output(rnn_output)\n",
        "        N, C, H = output.shape\n",
        "        output = output.view(N, H, C) # should permute be used here?\n",
        "        return F.softmax(output, dim=-1)"
      ],
      "metadata": {
        "id": "r30bdDwSA70q"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "num_embeddings = 27\n",
        "hidden_dim = 64\n",
        "output_dim = 27\n",
        "model = LanguageModel(\n",
        "    num_embeddings=num_embeddings,\n",
        "    hidden_dim=hidden_dim,\n",
        "    output_dim=output_dim\n",
        ")\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss = evaluate(model, val_dataloader, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlAD1m27IASw",
        "outputId": "b2f087a1-fef3-436c-82c6-a3ea0a0698f1"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:14<23:38, 14.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100, Train Loss: 3.2504, Val Loss: 3.2253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [02:38<21:14, 14.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Train Loss: 3.1340, Val Loss: 3.1358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 21/100 [05:01<19:00, 14.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Train Loss: 3.1127, Val Loss: 3.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [07:25<16:26, 14.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100, Train Loss: 3.1010, Val Loss: 3.1044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 41/100 [09:47<14:00, 14.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100, Train Loss: 3.0885, Val Loss: 3.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 51/100 [12:10<11:43, 14.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100, Train Loss: 3.0848, Val Loss: 3.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 61/100 [14:35<09:22, 14.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100, Train Loss: 3.0790, Val Loss: 3.0821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 71/100 [16:59<07:00, 14.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100, Train Loss: 3.0770, Val Loss: 3.0803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 81/100 [19:24<04:33, 14.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/100, Train Loss: 3.0748, Val Loss: 3.0774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 91/100 [21:48<02:06, 14.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/100, Train Loss: 3.0732, Val Loss: 3.0770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [23:54<00:00, 14.35s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    random_vals = encoded[:32]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars:\n",
        "    string = ''\n",
        "    for letter in char.tolist():\n",
        "        if letter == 0:\n",
        "            break\n",
        "        string += decoder[letter]\n",
        "    print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvhL5Wf_IbIf",
        "outputId": "06f70abe-2261-4fd7-a18b-33bc569e915e"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nabfdgabgblalaaaalagaaaaaca\n",
            "naefcgbffdnafaa\n",
            "nabddgfbgalflaaaalfhfcabaga\n",
            "mcddcgffm\n",
            "labbggaecdnafagabmbgbaabada\n",
            "mag\n",
            "nadfcgaffalbo\n",
            "nabedhaffdnafaaaalagaaaaacb\n",
            "madccgaf\n",
            "naeddgaffalfgaedalahfaalado\n",
            "naaccglcmenffalbamcfaaacaca\n",
            "nabdcabhfbofjaabalafaaalcdo\n",
            "naedclcbeblafaabalglgbcahcc\n",
            "nadfegaifalbo\n",
            "naedcgaebbnagaaaalagaaaaaca\n",
            "nabddgfffalaoaaedmchfcalado\n",
            "labbbhbenclanagablagaaaaada\n",
            "mab\n",
            "nadfegabnboagaaaalagaaacaga\n",
            "lagachcggfodgaaaaochfeacgga\n",
            "mabbgg\n",
            "nadbbgaegcmei\n",
            "nabfchdbfaobmabbalagaaaaacb\n",
            "malcdhcimcnagaaaalanaaacaga\n",
            "mag\n",
            "naaccaagfgmdgebe\n",
            "nabfcgaeeanagaacalafaababba\n",
            "nadbegdffanaoaaaal\n",
            "mabbgaahmanagbaaalafacaabcc\n",
            "nabbcgaggakagabablbgaaaabga\n",
            "nabcegaffanagaaaalagaaaabcb\n",
            "naeddgbgm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove embedding and add more layers to GRU\n",
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, num_embeddings, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings, output_dim)\n",
        "        # self.rnn = nn.GRU(hidden_dim, hidden_dim, num_layers=4, batch_first=True)\n",
        "        # self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x.long())\n",
        "        # rnn_output, _ = self.rnn(x)\n",
        "        # output = self.output(rnn_output)\n",
        "        N, H, C = x.shape\n",
        "        x = x.view(N * H, C) # should permute be used here?\n",
        "        return F.softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "lGYCr5QEV4EP"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    running_loss = 0.0\n",
        "    for idx, (X, y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X)\n",
        "        y = y.view(-1)\n",
        "        loss = criterion(y_pred, y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / (idx + 1)"
      ],
      "metadata": {
        "id": "DuS68GSIWHav"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_embeddings = 27\n",
        "output_dim = 27\n",
        "model = LanguageModel(\n",
        "    num_embeddings=num_embeddings,\n",
        "    output_dim=output_dim\n",
        ")\n",
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}/{epochs}, Train Loss: {train_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8hiV9t2WRVd",
        "outputId": "4a4a981d-05a7-4e42-9428-25c9a0ab1800"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:00<01:33,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100, Train Loss: 3.2637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [00:07<00:55,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Train Loss: 2.4841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 21/100 [00:14<00:56,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Train Loss: 2.3821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [00:20<00:42,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100, Train Loss: 2.3653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 41/100 [00:27<00:43,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100, Train Loss: 2.3603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 51/100 [00:33<00:29,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100, Train Loss: 2.3586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 61/100 [00:39<00:27,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100, Train Loss: 2.3579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 71/100 [00:46<00:17,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100, Train Loss: 2.3577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 81/100 [00:52<00:13,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/100, Train Loss: 2.3576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 91/100 [00:59<00:05,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/100, Train Loss: 2.3576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vals = torch.randperm(encoded.shape[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "    random_vals = encoded[vals[:32]]\n",
        "    predictions = model(random_vals)\n",
        "    predicted_chars = predictions.argmax(dim=-1)\n",
        "\n",
        "for char in predicted_chars.view(32, 16):\n",
        "    string = ''\n",
        "    for letter in char.tolist():\n",
        "        if letter == 0:\n",
        "            break\n",
        "        string += decoder[letter]\n",
        "    print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuvinzZMWcIm",
        "outputId": "14c0bb71-b19a-422c-d9e7-253925d7a6f3"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hassan\n",
            "columbus\n",
            "naiah\n",
            "kodi\n",
            "legacii\n",
            "cesia\n",
            "christen\n",
            "brycyn\n",
            "arraya\n",
            "kamorah\n",
            "piercen\n",
            "maize\n",
            "adaliz\n",
            "nysha\n",
            "corrin\n",
            "keigan\n",
            "honest\n",
            "hadly\n",
            "nery\n",
            "denny\n",
            "eilish\n",
            "aslynn\n",
            "afif\n",
            "lennen\n",
            "kelsey\n",
            "stran\n",
            "gabryelle\n",
            "koda\n",
            "kenrick\n",
            "saban\n",
            "philomina\n",
            "anzleigh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLDw7e97XF1e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}